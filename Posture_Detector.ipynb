{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiaidada/MHealth/blob/main/Posture_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TahTWNG9t20i"
      },
      "source": [
        "First, upload your files on Colab, and then Unzip it using the code below\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq3gBFpYHdFu",
        "outputId": "ada3140d-d5b1-41c2-fb03-dda7284a4109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  images.zip\n",
            "   creating: dataset_seven/images/\n",
            "   creating: dataset_seven/images/10_bad/\n",
            "  inflating: dataset_seven/images/10_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven/images/10_bad/bad (9).jpg  \n",
            "   creating: dataset_seven/images/10_good/\n",
            "  inflating: dataset_seven/images/10_good/bad (30).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (1).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (2).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (3).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (4).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (5).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (6).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (7).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (8).jpg  \n",
            "  inflating: dataset_seven/images/10_good/good (9).jpg  \n",
            "   creating: dataset_seven/images/1_bad/\n",
            "  inflating: dataset_seven/images/1_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (11).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven/images/1_bad/bad (9).jpg  \n",
            "   creating: dataset_seven/images/1_good/\n",
            "  inflating: dataset_seven/images/1_good/good (1).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (10).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (11).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (12).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (2).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (3).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (4).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (5).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (6).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (7).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (8).jpg  \n",
            "  inflating: dataset_seven/images/1_good/good (9).jpg  \n",
            "   creating: dataset_seven/images/2_bad/\n",
            "  inflating: dataset_seven/images/2_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven/images/2_bad/bad (9).jpg  \n",
            "   creating: dataset_seven/images/2_good/\n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM #8.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.56 PM.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.57 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/2_good/Photo on 2023-12-03 at 10.57 PM.jpg  \n",
            "   creating: dataset_seven/images/3_bad/\n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.58 PM.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.59 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/3_bad/Photo on 2023-12-03 at 10.59 PM.jpg  \n",
            "   creating: dataset_seven/images/3_good/\n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.58 PM #8.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #8.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 10.59 PM #9.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 11.00 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/3_good/Photo on 2023-12-03 at 11.00 PM.jpg  \n",
            "   creating: dataset_seven/images/4_bad/\n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.10 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.10 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.10 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.10 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.10 PM.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.11 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/4_bad/Photo on 2023-12-03 at 11.11 PM #4.jpg  \n",
            "   creating: dataset_seven/images/4_good/\n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.10 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.11 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.11 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.11 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.11 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.11 PM.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.12 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.12 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.12 PM.jpg  \n",
            "  inflating: dataset_seven/images/4_good/Photo on 2023-12-03 at 11.13 PM #2.jpg  \n",
            "   creating: dataset_seven/images/5_bad/\n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #8.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM #9.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.18 PM.jpg  \n",
            "  inflating: dataset_seven/images/5_bad/Photo on 2023-12-03 at 11.19 PM.jpg  \n",
            "   creating: dataset_seven/images/5_good/\n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.18 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.19 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.19 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.19 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.19 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.19 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.20 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.20 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.20 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/5_good/Photo on 2023-12-03 at 11.20 PM #5.jpg  \n",
            "   creating: dataset_seven/images/6_bad/\n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.23 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.23 PM.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.24 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.24 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.24 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.25 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.25 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.25 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/6_bad/Photo on 2023-12-03 at 11.26 PM.jpg  \n",
            "   creating: dataset_seven/images/6_good/\n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.25 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.25 PM.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.26 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.26 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.26 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.26 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.27 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.27 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.27 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/6_good/Photo on 2023-12-03 at 11.27 PM.jpg  \n",
            "   creating: dataset_seven/images/7_bad/\n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.28 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.28 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.28 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.28 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.28 PM.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.29 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.29 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.29 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/7_bad/Photo on 2023-12-03 at 11.29 PM.jpg  \n",
            "   creating: dataset_seven/images/7_good/\n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.29 PM #5.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #2.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #3.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #4.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #6.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #7.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #8.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM #9.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.30 PM.jpg  \n",
            "  inflating: dataset_seven/images/7_good/Photo on 2023-12-03 at 11.31 PM #2.jpg  \n",
            "   creating: dataset_seven/images/8_bad/\n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-17-09.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-20.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-26.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-31.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-38.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-44.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-50.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-18-55.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-19-00.jpg  \n",
            "  inflating: dataset_seven/images/8_bad/photo_2023-12-05_23-19-11.jpg  \n",
            "   creating: dataset_seven/images/8_good/\n",
            "  inflating: dataset_seven/images/8_good/.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-19-18.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-19-36.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-19-42.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-19-47.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-19-52.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-20-09.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-20-14.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-20-26.jpg  \n",
            "  inflating: dataset_seven/images/8_good/photo_2023-12-05_23-20-39.jpg  \n",
            "   creating: dataset_seven/images/9_bad/\n",
            "  inflating: dataset_seven/images/9_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (11).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (12).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (13).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (14).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (15).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (16).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (17).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (18).jpg  \n",
            "  inflating: dataset_seven/images/9_bad/bad (19).jpg  \n",
            "   creating: dataset_seven/images/9_good/\n",
            "  inflating: dataset_seven/images/9_good/good (1).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (10).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (2).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (3).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (4).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (5).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (6).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (7).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (8).jpg  \n",
            "  inflating: dataset_seven/images/9_good/good (9).jpg  \n",
            "Archive:  images_all.zip\n",
            "   creating: dataset_seven_all/images/\n",
            "   creating: dataset_seven_all/images/10_bad/\n",
            "  inflating: dataset_seven_all/images/10_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (11).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (12).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (13).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (14).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (15).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (16).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (17).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (18).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (19).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (20).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (21).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (22).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (23).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (24).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (25).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (26).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (27).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (28).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (29).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (31).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (32).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (33).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (34).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (35).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (36).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (37).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven_all/images/10_bad/bad (9).jpg  \n",
            "   creating: dataset_seven_all/images/10_good/\n",
            "  inflating: dataset_seven_all/images/10_good/bad (30).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (1).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (10).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (11).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (12).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (13).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (14).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (15).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (16).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (17).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (18).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (19).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (2).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (20).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (21).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (22).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (23).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (24).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (25).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (26).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (27).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (28).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (29).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (3).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (4).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (5).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (6).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (7).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (8).jpg  \n",
            "  inflating: dataset_seven_all/images/10_good/good (9).jpg  \n",
            "   creating: dataset_seven_all/images/1_bad/\n",
            "  inflating: dataset_seven_all/images/1_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (11).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven_all/images/1_bad/bad (9).jpg  \n",
            "   creating: dataset_seven_all/images/1_good/\n",
            "  inflating: dataset_seven_all/images/1_good/good (1).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (10).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (11).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (12).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (2).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (3).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (4).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (5).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (6).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (7).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (8).jpg  \n",
            "  inflating: dataset_seven_all/images/1_good/good (9).jpg  \n",
            "   creating: dataset_seven_all/images/2_bad/\n",
            "  inflating: dataset_seven_all/images/2_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven_all/images/2_bad/bad (9).jpg  \n",
            "   creating: dataset_seven_all/images/2_good/\n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.56 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.57 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/2_good/Photo on 2023-12-03 at 10.57 PM.jpg  \n",
            "   creating: dataset_seven_all/images/3_bad/\n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.58 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.59 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/3_bad/Photo on 2023-12-03 at 10.59 PM.jpg  \n",
            "   creating: dataset_seven_all/images/3_good/\n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.58 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 10.59 PM #9.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/3_good/Photo on 2023-12-03 at 11.00 PM.jpg  \n",
            "   creating: dataset_seven_all/images/4_bad/\n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.10 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.10 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.10 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.10 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.10 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.11 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/4_bad/Photo on 2023-12-03 at 11.11 PM #4.jpg  \n",
            "   creating: dataset_seven_all/images/4_good/\n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.10 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.11 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.11 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.11 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.11 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.11 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.12 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.12 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.12 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.12 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.12 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.13 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/4_good/Photo on 2023-12-03 at 11.13 PM.jpg  \n",
            "   creating: dataset_seven_all/images/5_bad/\n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM #9.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.18 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/5_bad/Photo on 2023-12-03 at 11.19 PM.jpg  \n",
            "   creating: dataset_seven_all/images/5_good/\n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.18 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.19 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.19 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.19 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.19 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.19 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/5_good/Photo on 2023-12-03 at 11.20 PM.jpg  \n",
            "   creating: dataset_seven_all/images/6_bad/\n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.23 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.23 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.24 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.24 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.24 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.25 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.25 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.25 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/6_bad/Photo on 2023-12-03 at 11.26 PM.jpg  \n",
            "   creating: dataset_seven_all/images/6_good/\n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.24 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.25 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.25 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.26 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.27 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.27 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.27 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/6_good/Photo on 2023-12-03 at 11.27 PM.jpg  \n",
            "   creating: dataset_seven_all/images/7_bad/\n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.28 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.28 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.28 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.28 PM #5.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.28 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.29 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.29 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.29 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/7_bad/Photo on 2023-12-03 at 11.29 PM #5.jpg  \n",
            "   creating: dataset_seven_all/images/7_good/\n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.29 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #3.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #4.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #6.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #7.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #8.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM #9.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.30 PM.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.31 PM #2.jpg  \n",
            "  inflating: dataset_seven_all/images/7_good/Photo on 2023-12-03 at 11.31 PM.jpg  \n",
            "   creating: dataset_seven_all/images/8_bad/\n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-17-09.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-20.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-26.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-31.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-38.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-44.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-50.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-18-55.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-19-00.jpg  \n",
            "  inflating: dataset_seven_all/images/8_bad/photo_2023-12-05_23-19-11.jpg  \n",
            "   creating: dataset_seven_all/images/8_good/\n",
            "  inflating: dataset_seven_all/images/8_good/.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-19-18.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-19-36.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-19-42.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-19-47.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-19-52.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-20-09.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-20-14.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-20-26.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-20-39.jpg  \n",
            "  inflating: dataset_seven_all/images/8_good/photo_2023-12-05_23-20-56.jpg  \n",
            "   creating: dataset_seven_all/images/9_bad/\n",
            "  inflating: dataset_seven_all/images/9_bad/bad (1).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (10).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (11).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (12).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (13).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (14).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (15).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (16).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (17).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (18).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (19).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (2).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (3).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (4).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (5).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (6).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (7).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (8).jpg  \n",
            "  inflating: dataset_seven_all/images/9_bad/bad (9).jpg  \n",
            "   creating: dataset_seven_all/images/9_good/\n",
            "  inflating: dataset_seven_all/images/9_good/good (1).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (10).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (11).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (12).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (13).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (14).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (15).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (16).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (2).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (3).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (4).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (5).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (6).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (7).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (8).jpg  \n",
            "  inflating: dataset_seven_all/images/9_good/good (9).jpg  \n"
          ]
        }
      ],
      "source": [
        "!unzip images.zip -d dataset_seven\n",
        "!unzip images_all.zip -d dataset_seven_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmrR77hdICnJ"
      },
      "source": [
        "Now, we will fix the data, this is only for our specific fileing system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1PLYvaZIADN",
        "outputId": "fb6382ca-8a71-44d0-83d2-1836f76011ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets created successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the main folder containing the subfolders\n",
        "main_folder_path = \"/content/dataset_seven/images\"\n",
        "\n",
        "# Define the root folder for the datasets\n",
        "root_dataset_folder = \"/content/dataset\"\n",
        "\n",
        "# Iterate through folders 1 to 7\n",
        "for x in range(1, 11):\n",
        "    # Define folder names for good and bad datasets\n",
        "    good_folder_name = f\"{x}_good\"\n",
        "    bad_folder_name = f\"{x}_bad\"\n",
        "\n",
        "    # Create dataset folders\n",
        "    dataset_folder_path = os.path.join(root_dataset_folder, f\"dataset_{x}\")\n",
        "    os.makedirs(dataset_folder_path, exist_ok=True)\n",
        "\n",
        "    # Process good files with label 0\n",
        "    good_folder_path = os.path.join(main_folder_path, good_folder_name)\n",
        "    good_dataset_path = os.path.join(dataset_folder_path, \"good\")\n",
        "    os.makedirs(good_dataset_path, exist_ok=True)\n",
        "    for file_name in os.listdir(good_folder_path):\n",
        "        file_path = os.path.join(good_folder_path, file_name)\n",
        "        shutil.copy(file_path, os.path.join(good_dataset_path, file_name))\n",
        "\n",
        "    # Process bad files with label 1\n",
        "    bad_folder_path = os.path.join(main_folder_path, bad_folder_name)\n",
        "    bad_dataset_path = os.path.join(dataset_folder_path, \"bad\")\n",
        "    os.makedirs(bad_dataset_path, exist_ok=True)\n",
        "    for file_name in os.listdir(bad_folder_path):\n",
        "        file_path = os.path.join(bad_folder_path, file_name)\n",
        "        shutil.copy(file_path, os.path.join(bad_dataset_path, file_name))\n",
        "\n",
        "\n",
        "print(\"Datasets created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHGaz4al_8xa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-LQ1HIk_9FB",
        "outputId": "901e3b46-077f-42a3-e415-e442e435c8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets created successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the main folder containing the subfolders\n",
        "main_folder_path = \"/content/dataset_seven_all/images\"\n",
        "\n",
        "# Define the root folder for the datasets\n",
        "root_dataset_folder = \"/content/dataset_all\"\n",
        "\n",
        "# Iterate through folders 1 to 7\n",
        "for x in range(1, 11):\n",
        "    # Define folder names for good and bad datasets\n",
        "    good_folder_name = f\"{x}_good\"\n",
        "    bad_folder_name = f\"{x}_bad\"\n",
        "\n",
        "    # Create dataset folders\n",
        "    dataset_folder_path = os.path.join(root_dataset_folder, f\"dataset_{x}\")\n",
        "    os.makedirs(dataset_folder_path, exist_ok=True)\n",
        "\n",
        "    # Process good files with label 0\n",
        "    good_folder_path = os.path.join(main_folder_path, good_folder_name)\n",
        "    good_dataset_path = os.path.join(dataset_folder_path, \"good\")\n",
        "    os.makedirs(good_dataset_path, exist_ok=True)\n",
        "    for file_name in os.listdir(good_folder_path):\n",
        "        file_path = os.path.join(good_folder_path, file_name)\n",
        "        shutil.copy(file_path, os.path.join(good_dataset_path, file_name))\n",
        "\n",
        "    # Process bad files with label 1\n",
        "    bad_folder_path = os.path.join(main_folder_path, bad_folder_name)\n",
        "    bad_dataset_path = os.path.join(dataset_folder_path, \"bad\")\n",
        "    os.makedirs(bad_dataset_path, exist_ok=True)\n",
        "    for file_name in os.listdir(bad_folder_path):\n",
        "        file_path = os.path.join(bad_folder_path, file_name)\n",
        "        shutil.copy(file_path, os.path.join(bad_dataset_path, file_name))\n",
        "\n",
        "\n",
        "print(\"Datasets created successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq8IAmQ3KjpB"
      },
      "source": [
        "Creating the dataset and adding the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ip7ujM7yKjMz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = ['good', 'bad']\n",
        "        self.file_paths, self.labels = self._load_file_paths_and_labels()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.file_paths[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def _load_file_paths_and_labels(self):\n",
        "        file_paths = []\n",
        "        labels = []\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_path = os.path.join(self.root_dir, class_name)\n",
        "            if os.path.exists(class_path):\n",
        "                class_label = 0 if class_name == 'good' else 1\n",
        "                for filename in os.listdir(class_path):\n",
        "                    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        file_paths.append(os.path.join(class_path, filename))\n",
        "                        labels.append(class_label)\n",
        "\n",
        "        return file_paths, labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCeqJSAeLvIE"
      },
      "source": [
        "Training with RGB images of size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2R94VDsEM6kY"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "def train(epochs , net , train_loader ):\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs.unsqueeze(0), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "  end_time = time.time()\n",
        "  training_time = end_time - start_time\n",
        "  print(f'Training Time: {training_time:.2f} seconds')\n",
        "  print('Finished Training')\n",
        "  return training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5ynzL1LGPzg7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images, labels\n",
        "            outputs = model(images)\n",
        "            total_correct = total_correct+1 if outputs.argmax() == labels else total_correct\n",
        "            total_samples +=1\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7J8qlGRKy6u",
        "outputId": "0c521d3d-21d2-4113-84b3-c30997adfbb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 152.71 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 151.55 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.47 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.65 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 152.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 152.03 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 151.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.21 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 152.42 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 126.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 127.59 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 127.90 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 126.31 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 125.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 126.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 125.79 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 125.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 125.48 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 127.13 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.13 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.27 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.45 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 118.92 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 120.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.81 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.27 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 120.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 120.31 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 119.66 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 110.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8462 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 111.04 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 112.42 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 111.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 110.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 110.68 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 110.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 113.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 112.26 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 111.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.35 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 128.38 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 129.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.78 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 129.92 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 129.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.21 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 129.51 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.72 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 127.65 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 131.53 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.43 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.04 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 129.03 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.26 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.04 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.46 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 127.51 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 127.80 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.6000 7\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 129.08 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 129.86 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 130.14 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 130.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 129.68 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 128.75 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 101.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.15 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.59 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.90 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 101.68 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 99.83 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 101.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.22 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 107.30 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.61 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.10 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.80 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.48 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.27 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.30 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.16 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.45 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 106.16 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 102.94 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.84 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 105.57 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.54 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 103.48 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.05 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 104.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2500)\n",
        "        self.fc2 = nn.Linear(2500, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset/dataset_{i}', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some people had regestared more than 10 photos, thus, we first deleted random photo from each person so that the comparision is fair for everyone.\n",
        "\n",
        "Also, since our dataset is quite small"
      ],
      "metadata": {
        "id": "C9jhGlNZ6M4j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlo09_6PA62A",
        "outputId": "a6821c9e-7c21-4daa-b206-5e5c0ed8dbcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1526.785171508789, 1264.4718692302704, 1196.7991392612457, 1113.7084741592407, 1289.7367677688599, 1285.0790226459503, 1292.0624506473541, 1010.5748569965363, 1050.4389324188232, 1041.4965760707855]\n",
            "[10.0, 10.0, 10.0, 9.846153846153847, 10.0, 10.0, 9.6, 10.0, 10.0, 10.0]\n",
            "[9.8, 9.25, 10.0, 8.5, 9.5, 9.5, 9.0, 10.0, 10.0, 10.0]\n"
          ]
        }
      ],
      "source": [
        "print(train_times)\n",
        "print(train_acc)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb7jGZleL--W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTj0i-JTBvCA",
        "outputId": "5af66cda-e6b7-4f31-eca0-66af23894aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 153.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 160.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 167.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 154.82 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 154.91 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 154.06 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.61 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 153.25 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 154.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 135.89 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 141.47 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.99 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 136.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 135.78 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 138.49 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 137.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 136.46 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 137.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 138.16 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 165.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 165.08 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 161.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 164.54 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 162.92 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 163.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 162.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 163.94 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 163.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 164.00 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 138.59 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 139.44 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.72 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 137.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 138.46 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 138.55 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 137.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 135.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 136.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 136.75 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 145.39 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 145.68 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 145.22 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 144.44 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 144.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 145.97 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.46 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.35 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.71 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.21 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 144.70 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 142.93 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 144.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.51 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.47 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 142.17 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 144.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 143.82 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 132.94 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 135.92 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 134.25 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 132.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 134.17 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 132.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 133.93 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 141.21 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 133.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 132.57 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 99.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 98.71 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 98.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 108.66 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 99.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 98.67 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 99.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 98.70 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 100.05 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 110.72 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 191.59 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 182.68 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 191.38 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2500)\n",
        "        self.fc2 = nn.Linear(2500, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset_all/dataset_{i}', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "RukNzaQ2B9mq",
        "outputId": "37f486e4-9fb8-4a45-ab27-1b5582330615"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bd871545b68f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_times' is not defined"
          ]
        }
      ],
      "source": [
        "print(train_times)\n",
        "print(train_acc)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4KLt92cE5xK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d0f328-a6b2-4202-93df-5084307b8171",
        "id": "Gb5LU9hN52t_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 141.76 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.53 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 154.04 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 142.83 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 139.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 141.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 139.95 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.95 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 140.30 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 335.67 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 0.9286\n",
            "Training Time: 466.65 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 408.18 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 272.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 268.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 268.26 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 265.86 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 265.94 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 266.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 266.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2500)\n",
        "        self.fc2 = nn.Linear(2500, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(9 , 11):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset_all/dataset_{i}', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_times)\n",
        "print(train_acc)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDGakIXWNtL1",
        "outputId": "1cf2b4bd-212f-4b59-8b26-e5ce6386c844"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 1421.979721069336, 3084.0177671909332]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 10.0, 10.0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 10.0, 9.928571428571429]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46b2ac9-8f1b-4227-a596-b1e1f5392518",
        "id": "IpfRP-UjNtqf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 70.07 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8889 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 71.15 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.84 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.66 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.66 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 68.38 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 70.01 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 69.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.42 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 61.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.34 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.91 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.22 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 74.28 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 76.63 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 71.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 74.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 72.27 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 71.65 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 72.55 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 72.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 71.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 73.58 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 61.53 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.53 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.30 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.72 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 66.74 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 64.03 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 66.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 64.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 65.14 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 65.10 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 64.70 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 65.55 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 64.55 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 64.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 67.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5882 6\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 66.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5882 6\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 64.93 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.6471 6\n",
            "Test Accuracy: 0.4000\n",
            "Training Time: 64.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 65.01 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 68.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 65.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 67.52 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 68.92 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 67.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 63.78 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.6250 7\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 64.99 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 63.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.7500 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 62.84 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 64.51 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.79 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.80 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 60.39 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 62.35 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 61.05 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 7\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.17 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 29.59 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.50 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.78 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.26 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 29.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 58.97 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 59.25 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.90 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.16 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 59.53 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 58.05 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.90 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.07 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.90 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 57.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 125.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 0.7857\n",
            "Training Time: 194.34 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 0.9286\n",
            "Training Time: 169.13 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 115.24 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 107.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 107.47 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 106.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 108.14 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 107.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 107.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(3, 8, 5)\n",
        "        self.fc1 = nn.Linear(3016, 2500)\n",
        "        self.fc2 = nn.Linear(2500, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.Grayscale(), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset_all/dataset_{i}', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_times)\n",
        "print(train_acc)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599b5fb8-265b-4688-b9b5-6ff1a31a5974",
        "id": "_Ff3KH2limX9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[697.2346720695496, 609.7096183300018, 730.480382680893, 616.0819199085236, 651.5504660606384, 666.3675916194916, 628.8221390247345, 295.247674703598, 581.1068634986877, 1249.113710641861]\n",
            "[9.88888888888889, 10.0, 10.0, 10.0, 10.0, 8.823529411764707, 8.9375, 10.0, 10.0, 10.0]\n",
            "[9.8, 9.75, 9.8, 9.75, 9.2, 8.6, 7.75, 9.8, 10.0, 9.714285714285715]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840246e5-79bf-4ae0-abb3-1d1e98ad1399",
        "id": "AsImsIjQishV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 44.97 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5556 1\n",
            "Test Accuracy: 0.4000\n",
            "Training Time: 44.22 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8889 1\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 45.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.9444 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 45.60 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 44.30 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 45.10 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 44.44 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 45.74 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 45.52 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 45.61 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.08 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8125 2\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 39.33 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.21 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 40.42 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.08 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 38.83 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.19 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.27 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 2\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 47.12 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.6842 3\n",
            "Test Accuracy: 0.6000\n",
            "Training Time: 47.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 46.97 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 47.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 48.42 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 46.37 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 48.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 47.54 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 46.76 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 47.43 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 3\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.91 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 40.97 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8750 4\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 39.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 39.84 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 40.03 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.95 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 40.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.95 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.39 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 39.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 4\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.15 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8235 5\n",
            "Test Accuracy: 0.4000\n",
            "Training Time: 42.06 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.26 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.91 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 43.38 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.00 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.70 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.73 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.29 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.64 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 5\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.89 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.7059 6\n",
            "Test Accuracy: 0.2000\n",
            "Training Time: 41.98 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5294 6\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 42.54 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.9412 6\n",
            "Test Accuracy: 0.2000\n",
            "Training Time: 41.91 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.81 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.78 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 43.47 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.05 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 42.06 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 41.80 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 6\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 38.88 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5000 7\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 38.84 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.0000\n",
            "Training Time: 39.20 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.6250 7\n",
            "Test Accuracy: 0.2500\n",
            "Training Time: 40.22 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 39.14 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.0000\n",
            "Training Time: 39.40 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5000 7\n",
            "Test Accuracy: 0.7500\n",
            "Training Time: 39.45 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.0000\n",
            "Training Time: 39.32 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 39.65 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.5000\n",
            "Training Time: 40.49 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.5625 7\n",
            "Test Accuracy: 0.0000\n",
            "Training Time: 8.93 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.8125 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.06 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 0.8000\n",
            "Training Time: 8.76 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 7.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.94 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.83 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 7.93 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.85 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 8.87 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 8\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 19.36 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 0.9643 9\n",
            "Test Accuracy: 0.8571\n",
            "Training Time: 20.67 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 19.35 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 20.45 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 19.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 20.39 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 19.08 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 20.18 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 19.16 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 21.35 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 9\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.63 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 0.7857\n",
            "Training Time: 38.56 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.75 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 36.96 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 36.43 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 38.11 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.69 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.51 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n",
            "Training Time: 37.41 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 10\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(3, 8, 5)\n",
        "        self.fc1 = nn.Linear(520, 256)\n",
        "        self.fc2 = nn.Linear(256, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((64, 32)), transforms.Grayscale(), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset_all/dataset_{i}', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_times)\n",
        "print(train_acc)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOBjPuXAi2ae",
        "outputId": "7d5af925-3081-4bbb-d1ef-ae9de9a5b29d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[451.1539282798767, 392.89325761795044, 473.22388195991516, 401.5898687839508, 422.1093168258667, 422.3021614551544, 394.587438583374, 85.8764476776123, 199.3914976119995, 375.46871614456177]\n",
            "[9.38888888888889, 9.8125, 9.68421052631579, 9.4375, 9.823529411764707, 9.176470588235293, 5.5625, 9.8125, 9.964285714285715, 10.0]\n",
            "[8.6, 9.5, 9.4, 8.75, 9.4, 8.2, 2.75, 9.8, 9.857142857142858, 9.785714285714285]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination folders\n",
        "source_base_folder = \"/content/dataset_all\"\n",
        "destination_folder = \"/content/dataset_all_2\"\n",
        "\n",
        "# Create destination folders if they don't exist\n",
        "os.makedirs(os.path.join(destination_folder, 'bad'), exist_ok=True)\n",
        "os.makedirs(os.path.join(destination_folder, 'good'), exist_ok=True)\n",
        "\n",
        "# Iterate through the dataset folders\n",
        "for i in range(1 , 11):  # Assuming your folders are numbered from 0 to 10\n",
        "    source_bad_folder = os.path.join(source_base_folder, f\"dataset_{i}/bad\")\n",
        "    source_good_folder = os.path.join(source_base_folder, f\"dataset_{i}/good\")\n",
        "\n",
        "    # Move bad images to the combined 'bad' folder\n",
        "    for filename in os.listdir(source_bad_folder):\n",
        "        source_path = os.path.join(source_bad_folder, filename)\n",
        "        destination_path = os.path.join(destination_folder, 'bad', filename)\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "    # Move good images to the combined 'good' folder\n",
        "    for filename in os.listdir(source_good_folder):\n",
        "        source_path = os.path.join(source_good_folder, filename)\n",
        "        destination_path = os.path.join(destination_folder, 'good', filename)\n",
        "        shutil.move(source_path, destination_path)\n",
        "\n",
        "print(\"Image combination completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3REkV0QUZh",
        "outputId": "4e086622-1f90-405b-ce57-5058c4225883"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image combination completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "4ba363ea-f383-4b6e-e112-3fbe7b972245",
        "id": "Fyg27BxgRBK9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 1081.09 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.8049\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f436bc558d90>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtime_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4c8f79f26ebb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, net, train_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop over the dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-f82398c4570e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \"\"\"\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 )\n\u001b[1;32m   2191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 2):\n",
        "  net = Net()\n",
        "  dataset = CustomDataset(root_dir= f'/content/dataset_all_2', transform= transforms)\n",
        "  for j in range(10):\n",
        "\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "    val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "    time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "    train_times[i-1] += time_train\n",
        "    train_accuracy = evaluate_model(net, train_loader)\n",
        "    print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "    train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "    test_accuracy = evaluate_model(net, val_loader)\n",
        "    print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "    test_acc[i-1]+= test_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define the source and destination folders\n",
        "source_base_folder = \"/content/dataset\"\n",
        "destination_base_folder = \"/content/dataset-3\"\n",
        "\n",
        "# Create destination folders if they don't exist\n",
        "for folder_type in ['bad', 'good']:\n",
        "    os.makedirs(os.path.join(destination_base_folder, folder_type), exist_ok=True)\n",
        "\n",
        "# Get a list of dataset folders\n",
        "dataset_folders = [f\"dataset_{i}\" for i in range(1 , 11)]\n",
        "\n",
        "# Perform the process 10 times\n",
        "for iteration in range(1 , 11):\n",
        "    # Randomly shuffle the dataset folders\n",
        "    random.shuffle(dataset_folders)\n",
        "\n",
        "    # Leave out one dataset\n",
        "    dataset_to_exclude = dataset_folders.pop()\n",
        "\n",
        "    # Define the destination folder for the current iteration\n",
        "    destination_folder = os.path.join(destination_base_folder, f\"iteration_{iteration}\")\n",
        "\n",
        "    # Create destination folders for the current iteration\n",
        "    for folder_type in ['bad', 'good']:\n",
        "        os.makedirs(os.path.join(destination_folder, folder_type), exist_ok=True)\n",
        "\n",
        "    # Iterate through the remaining dataset folders\n",
        "    for dataset_folder in dataset_folders:\n",
        "        for folder_type in ['bad', 'good']:\n",
        "            source_subfolder = os.path.join(source_base_folder, f\"{dataset_folder}/{folder_type}\")\n",
        "            destination_subfolder = os.path.join(destination_folder, folder_type)\n",
        "\n",
        "            # Move images to the combined subfolder\n",
        "            for filename in os.listdir(source_subfolder):\n",
        "                source_path = os.path.join(source_subfolder, filename)\n",
        "                destination_path = os.path.join(destination_subfolder, filename)\n",
        "                shutil.move(source_path, destination_path)\n",
        "\n",
        "    print(f\"Iteration {iteration + 1} completed. Excluded dataset: {dataset_to_exclude}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR_7PdohUVLB",
        "outputId": "3e614ae3-c25f-4d88-8e25-53578c8e40f2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 completed. Excluded dataset: dataset_4\n",
            "Iteration 3 completed. Excluded dataset: dataset_1\n",
            "Iteration 4 completed. Excluded dataset: dataset_9\n",
            "Iteration 5 completed. Excluded dataset: dataset_6\n",
            "Iteration 6 completed. Excluded dataset: dataset_2\n",
            "Iteration 7 completed. Excluded dataset: dataset_8\n",
            "Iteration 8 completed. Excluded dataset: dataset_10\n",
            "Iteration 9 completed. Excluded dataset: dataset_5\n",
            "Iteration 10 completed. Excluded dataset: dataset_3\n",
            "Iteration 11 completed. Excluded dataset: dataset_7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = [4 , 1 ,9,6,2,8,10,5,3,7]"
      ],
      "metadata": {
        "id": "FcqT_sg9Z8iV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "\n",
        "\n",
        "  train_size = int(0.8 * len(dataset))\n",
        "  val_size = len(dataset) - train_size\n",
        "  train_set = CustomDataset(root_dir= f'/content/dataset-3/iteration_{i}', transform= transforms)\n",
        "  val_set = CustomDataset(root_dir= f'/content/dataset/dataset_{my_list[i-1]}', transform= transforms)\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "  val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "  time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "  train_times[i-1] += time_train\n",
        "  train_accuracy = evaluate_model(net, train_loader)\n",
        "  print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "  train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "  test_accuracy = evaluate_model(net, val_loader)\n",
        "  print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "  test_acc[i-1]+= test_accuracy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "bA9FGMjEaDAw",
        "outputId": "c1888781-5f27-4833-b5d3-affc1d58719a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 1015.86 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.6471\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5bf3bb634bec>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf'/content/dataset/dataset_{my_list[i-1]}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip leave_2.zip -d leave2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPp9hsSrrbHw",
        "outputId": "fc5bed2d-0657-4a36-aa50-496a57ed7931"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  leave_2.zip\n",
            "   creating: leave2/leave_2/\n",
            "   creating: leave2/leave_2/test/\n",
            "   creating: leave2/leave_2/test/bad/\n",
            "  inflating: leave2/leave_2/test/bad/bad (11).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (12).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (13).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (14).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (15).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (16).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (17).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (18).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (19).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (20).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (21).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (22).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (23).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (24).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (25).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (26).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (27).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (28).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (29).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (30).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (31).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (32).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (33).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (34).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (35).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (36).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (37).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (38).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (39).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (40).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (41).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (42).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (43).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (44).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (45).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (46).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (47).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (48).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (49).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (50).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (51).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (52).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (53).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (54).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (55).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (56).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (57).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (58).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (59).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (60).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (61).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (62).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (63).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (64).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (65).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/bad (66).jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.58 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.59 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 10.59 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.10 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.10 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.10 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.10 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.10 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.11 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.11 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM #9.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.18 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.19 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.23 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.23 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.24 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.24 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.24 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.25 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.25 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.25 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.26 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.28 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.28 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.28 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.28 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.28 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.29 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.29 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.29 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/Photo on 2023-12-03 at 11.29 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-17-09.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-20.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-26.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-31.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-38.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-44.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-50.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-18-55.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-19-00.jpg  \n",
            "  inflating: leave2/leave_2/test/bad/photo_2023-12-05_23-19-11.jpg  \n",
            "   creating: leave2/leave_2/test/good/\n",
            "  inflating: leave2/leave_2/test/good/.jpg  \n",
            "  inflating: leave2/leave_2/test/good/bad (30).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (1).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (10).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (11).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (12).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (13).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (14).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (15).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (16).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (17).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (18).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (19).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (2).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (20).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (21).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (22).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (23).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (24).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (25).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (26).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (27).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (28).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (29).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (3).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (30).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (31).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (32).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (33).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (34).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (35).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (36).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (37).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (38).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (39).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (4).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (40).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (41).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (5).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (6).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (7).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (8).jpg  \n",
            "  inflating: leave2/leave_2/test/good/good (9).jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.58 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 10.59 PM #9.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.00 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.10 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.11 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.11 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.11 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.11 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.11 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.12 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.12 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.12 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.12 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.12 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.13 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.13 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.18 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.19 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.19 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.19 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.19 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.19 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.20 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.24 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.25 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.25 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.26 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.27 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.27 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.27 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.27 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.29 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM #9.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.30 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.31 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/test/good/Photo on 2023-12-03 at 11.31 PM.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-19-18.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-19-36.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-19-42.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-19-47.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-19-52.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-20-09.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-20-14.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-20-26.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-20-39.jpg  \n",
            "  inflating: leave2/leave_2/test/good/photo_2023-12-05_23-20-56.jpg  \n",
            "   creating: leave2/leave_2/valid/\n",
            "   creating: leave2/leave_2/valid/bad/\n",
            "  inflating: leave2/leave_2/valid/bad/bad (1).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (10).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (2).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (3).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (4).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (5).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (6).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (7).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (8).jpg  \n",
            "  inflating: leave2/leave_2/valid/bad/bad (9).jpg  \n",
            "   creating: leave2/leave_2/valid/good/\n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #3.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #4.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #5.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #6.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #7.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM #8.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.56 PM.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.57 PM #2.jpg  \n",
            "  inflating: leave2/leave_2/valid/good/Photo on 2023-12-03 at 10.57 PM.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nERBc9tfr1Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "\n",
        "\n",
        "  train_size = int(0.8 * len(dataset))\n",
        "  val_size = len(dataset) - train_size\n",
        "  train_set = CustomDataset(root_dir= f'/content/leave1/leave_1/test', transform= transforms)\n",
        "  val_set = CustomDataset(root_dir= f'/content/leave1/leave_1/valid', transform= transforms)\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "  val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "  time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "  train_times[i-1] += time_train\n",
        "  train_accuracy = evaluate_model(net, train_loader)\n",
        "  print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "  train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "  test_accuracy = evaluate_model(net, val_loader)\n",
        "  print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "  test_acc[i-1]+= test_accuracy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "6a5d6695-313f-4a16-87f6-0d7e76a63a40",
        "id": "lkkFszFnr1nf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 1750.48 seconds\n",
            "Finished Training\n",
            "Training Accuracy: 1.0000 1\n",
            "Test Accuracy: 0.5652\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-80d47984d87c>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mtime_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0mtrain_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-4c8f79f26ebb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, net, train_loader)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(6032, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 84)\n",
        "        self.fc3 = nn.Linear(84, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "transforms = transforms.Compose([transforms.Resize((128, 64)), transforms.ToTensor()])\n",
        "train_times = [0]*10\n",
        "train_acc= [0]*10\n",
        "test_acc = [0]*10\n",
        "\n",
        "for i in range(1 , 11):\n",
        "  net = Net()\n",
        "\n",
        "\n",
        "\n",
        "  train_set = CustomDataset(root_dir= f'/content/leave2/leave_2/test', transform= transforms)\n",
        "  val_set = CustomDataset(root_dir= f'/content/leave2/leave_2/valid', transform= transforms)\n",
        "\n",
        "  train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
        "  val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
        "\n",
        "  time_train = train(epochs=50 , net= net, train_loader= train_loader )\n",
        "  train_times[i-1] += time_train\n",
        "  train_accuracy = evaluate_model(net, train_loader)\n",
        "  print(f'Training Accuracy: {train_accuracy:.4f}' , i)\n",
        "  train_acc[i-1]+= train_accuracy\n",
        "    # Evaluate the model on the test set\n",
        "  test_accuracy = evaluate_model(net, val_loader)\n",
        "  print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "  test_acc[i-1]+= test_accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "u_n-ncSTz8iV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJJeYGdJVwdBzYn8hDeG3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}